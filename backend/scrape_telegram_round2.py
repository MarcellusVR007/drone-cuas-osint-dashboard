#!/usr/bin/env python3
"""
Round 2: Enhanced Telegram Scraper - More Targeted Keywords
Focus on specific infrastructure targets and shorter timeframe
"""

import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from dotenv import load_dotenv
from telethon import TelegramClient
from telethon.tl.types import Channel
from telethon.errors import SessionPasswordNeededError
import re

# Load environment variables
load_dotenv()

# Telegram API credentials
API_ID = int(os.getenv('TELEGRAM_API_ID'))
API_HASH = os.getenv('TELEGRAM_API_HASH')

# Session file (stores authentication)
SESSION_NAME = 'osint_session'

# Target channels from research
TARGET_CHANNELS = [
    'grey_zone',          # Grey Zone - Wagner affiliated, 550k subs
    'intelslava',         # Intel Slava Z - Russian news aggregator
    'Warhronika',         # Military Chronicle
    'neuesausrussland',   # Alina Lipp - 175k followers
    'rybar',              # Rybar - OSINT/military analysis
    'voenacher',          # Voenkor - military correspondent
    'reverse_side_medal', # Wagner-linked media
]

# ENHANCED KEYWORDS - More specific infrastructure targets
LOCATION_KEYWORDS = [
    # Belgium
    'belgium', 'belgiÃ«', 'belgique', 'belgian', 'Ğ±ĞµĞ»ÑŒĞ³Ğ¸Ñ',
    'doel', 'tihange', 'borssele',  # Nuclear plants
    'liÃ¨ge', 'liege', 'luik', 'Ğ»ÑŒĞµĞ¶',
    'brunssum', 'maastricht', 'limburg',
    'brussels', 'bruxelles', 'brussel', 'Ğ±Ñ€ÑÑÑĞµĞ»ÑŒ',
    'antwerp', 'antwerpen', 'Ğ°Ğ½Ñ‚Ğ²ĞµÑ€Ğ¿ĞµĞ½',
    'charleroi', 'zaventem',  # Belgium airports

    # Netherlands
    'netherlands', 'nederland', 'Ğ½Ğ¸Ğ´ĞµÑ€Ğ»Ğ°Ğ½Ğ´Ñ‹', 'holland',
    'schiphol', 'amsterdam airport', 'eham',
    'rotterdam', 'rotterdam port', 'Ñ€Ğ¾Ñ‚Ñ‚ĞµÑ€Ğ´Ğ°Ğ¼',
    'eindhoven', 'maastricht',

    # Poland
    'poland', 'polska', 'Ğ¿Ğ¾Ğ»ÑŒÑˆĞ°',
    'warsaw', 'warszawa', 'Ğ²Ğ°Ñ€ÑˆĞ°Ğ²Ğ°',
    'gdansk', 'krakow', 'krakÃ³w', 'ĞºÑ€Ğ°ĞºĞ¾Ğ²',
    'trzebinia', 'czechowice', 'jedlicze',  # Oil refineries from Post #397

    # Germany
    'germany', 'deutschland', 'Ğ³ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ',
    'frankfurt', 'berlin', 'munich',
]

# Enhanced intel keywords
INTEL_KEYWORDS = [
    # Surveillance/Intel gathering
    'surveillance', 'reconnaissance', 'Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğµ', 'Ñ€Ğ°Ğ·Ğ²ĞµĞ´ĞºĞ°',
    'monitor', 'watch', 'observe', 'track', 'monitor',
    'photograph', 'photo', 'video', 'record', 'Ñ„Ğ¾Ñ‚Ğ¾', 'Ğ²Ğ¸Ğ´ĞµĞ¾',
    'location', 'coordinates', 'gps', 'map', 'ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ñ‹',

    # Payment/Bounty
    'payment', 'bounty', 'reward', 'Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ğ°', 'Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ',
    'bitcoin', 'btc', 'crypto', 'cryptocurrency', 'wallet',
    'euro', 'dollar', 'usd', 'eur', 'â‚¬', '$',

    # Recruitment
    'recruit', 'recruitment', 'task', 'mission', 'Ñ€ĞµĞºÑ€ÑƒÑ‚', 'Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°',
    'need', 'looking for', 'hire', 'Ğ¸Ñ‰Ñƒ', 'Ğ½ÑƒĞ¶ĞµĞ½',
    'contact', 'apply', 'telegram', 'bot', 'Ğ±Ğ¾Ñ‚', 'ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚',

    # Targets
    'nuclear', 'airport', 'Ğ°ÑÑ€Ğ¾Ğ¿Ğ¾Ñ€Ñ‚', 'refinery', 'Ğ½Ğ¿Ğ·',
    'military', 'army', 'base', 'Ğ²Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹', 'Ğ±Ğ°Ğ·Ğ°',
    'nato', 'otan', 'Ğ½Ğ°Ñ‚Ğ¾',
    'infrastructure', 'facility', 'infrastructure', 'Ğ¾Ğ±ÑŠĞµĞºÑ‚',
    'drone', 'uav', 'Ğ±Ğ¿Ğ»Ğ°', 'Ğ´Ñ€Ğ¾Ğ½',

    # Vulnerability analysis
    'vulnerable', 'weakness', 'gap', 'security', 'ÑƒÑĞ·Ğ²Ğ¸Ğ¼',
    'attack', 'strike', 'target', 'hit', 'Ğ°Ñ‚Ğ°ĞºĞ°', 'ÑƒĞ´Ğ°Ñ€',
]

# Payment patterns
PAYMENT_PATTERNS = [
    r'\$\s*\d+[,.]?\d*',           # $500, $1,000
    r'â‚¬\s*\d+[,.]?\d*',            # â‚¬500, â‚¬1.000
    r'\d+[,.]?\d*\s*(usd|eur|btc)', # 500 USD, 1000 EUR
    r'bitcoin\s+address',
    r'wallet\s*:\s*\w+',
    r'bc1[a-zA-Z0-9]{25,}',        # Bitcoin bech32
    r'[13][a-km-zA-HJ-NP-Z1-9]{25,}', # Bitcoin legacy
]

OUTPUT_DIR = "backend/scraped_data"
os.makedirs(OUTPUT_DIR, exist_ok=True)


def extract_payment_info(text: str) -> Dict:
    """Extract payment amounts and crypto addresses"""
    payment_info = {
        'amount': None,
        'currency': None,
        'crypto_address': None
    }

    text_lower = text.lower()

    # Check for payment amounts
    for pattern in PAYMENT_PATTERNS[:3]:
        match = re.search(pattern, text_lower)
        if match:
            amount_str = match.group(0)
            # Extract number
            numbers = re.findall(r'\d+[,.]?\d*', amount_str)
            if numbers:
                payment_info['amount'] = float(numbers[0].replace(',', ''))
            # Extract currency
            if '$' in amount_str or 'usd' in amount_str:
                payment_info['currency'] = 'USD'
            elif 'â‚¬' in amount_str or 'eur' in amount_str:
                payment_info['currency'] = 'EUR'
            elif 'btc' in amount_str or 'bitcoin' in amount_str:
                payment_info['currency'] = 'BTC'
            break

    # Check for crypto addresses
    for pattern in PAYMENT_PATTERNS[3:]:
        match = re.search(pattern, text)
        if match:
            payment_info['crypto_address'] = match.group(0)
            break

    return payment_info


def message_is_relevant(text: str) -> tuple[bool, int]:
    """Check if message is relevant, return (is_relevant, score)"""
    if not text:
        return False, 0

    text_lower = text.lower()
    score = 0

    # Location keyword match
    location_matches = sum(1 for keyword in LOCATION_KEYWORDS if keyword.lower() in text_lower)
    score += location_matches * 3  # High weight for location

    # Intel keyword match
    intel_matches = sum(1 for keyword in INTEL_KEYWORDS if keyword.lower() in text_lower)
    score += intel_matches * 2

    # Payment info present
    payment = extract_payment_info(text)
    if payment['amount']:
        score += 5
    if payment['crypto_address']:
        score += 5

    # Relevance threshold
    is_relevant = score >= 3  # Need at least 1 location or intel match with payment

    return is_relevant, score


async def scrape_channel(client: TelegramClient, channel_username: str,
                        start_date: datetime, end_date: datetime) -> List[Dict]:
    """Scrape a single channel"""

    print(f"\nğŸ“¡ Scraping @{channel_username}...")

    try:
        entity = await client.get_entity(channel_username)

        if not isinstance(entity, Channel):
            print(f"   âš ï¸  Not a channel, skipping")
            return []

        posts = []
        total_messages = 0
        relevant_messages = 0

        # Get messages in date range
        async for message in client.iter_messages(entity, offset_date=end_date, reverse=False):
            total_messages += 1

            # Make timezone naive for comparison
            message_date = message.date.replace(tzinfo=None) if message.date.tzinfo else message.date
            start_naive = start_date.replace(tzinfo=None) if start_date.tzinfo else start_date

            # Stop if before start date
            if message_date < start_naive:
                break

            # Only process text messages
            if not message.text:
                continue

            # Check relevance
            is_relevant, relevance_score = message_is_relevant(message.text)

            if is_relevant:
                relevant_messages += 1

                # Extract payment info
                payment = extract_payment_info(message.text)

                post_data = {
                    'message_id': message.id,
                    'channel': channel_username,
                    'channel_name': entity.title,
                    'date': message.date.isoformat(),
                    'text': message.text,
                    'url': f"https://t.me/{channel_username}/{message.id}",
                    'views': message.views or 0,
                    'forwards': message.forwards or 0,
                    'relevance_score': relevance_score,
                    'payment_amount': payment['amount'],
                    'payment_currency': payment['currency'],
                    'crypto_address': payment['crypto_address'],
                }

                posts.append(post_data)

        print(f"   âœ… Processed {total_messages} messages, {relevant_messages} relevant")
        return posts

    except Exception as e:
        print(f"   âŒ Error scraping {channel_username}: {e}")
        return []


async def main():
    """Main scraping function"""

    print("=" * 80)
    print("TELEGRAM OSINT SCRAPER - ROUND 2 (Enhanced Targeting)")
    print("=" * 80)

    # Date range - last 60 days only
    end_date = datetime.now()
    start_date = end_date - timedelta(days=60)

    print(f"\nğŸ“… Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")
    print(f"ğŸ“Š Location keywords: {len(LOCATION_KEYWORDS)}")
    print(f"ğŸ“Š Intel keywords: {len(INTEL_KEYWORDS)}")
    print(f"ğŸ“Š Target channels: {len(TARGET_CHANNELS)}")

    # Initialize Telegram client
    client = TelegramClient(SESSION_NAME, API_ID, API_HASH)

    await client.start()
    print("\nâœ… Telegram client authenticated")

    # Scrape all channels
    all_posts = []

    for channel in TARGET_CHANNELS:
        posts = await scrape_channel(client, channel, start_date, end_date)
        all_posts.extend(posts)
        await asyncio.sleep(2)  # Rate limiting

    # Sort by relevance score
    all_posts.sort(key=lambda x: x['relevance_score'], reverse=True)

    # Save results
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Save ALL relevant posts (not just top 100)
    output_file = f"{OUTPUT_DIR}/telegram_round2_all_{timestamp}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_posts, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 80)
    print("SCRAPING COMPLETE")
    print("=" * 80)
    print(f"ğŸ“Š Total relevant posts: {len(all_posts)}")
    print(f"ğŸ’¾ Saved to: {output_file}")

    if len(all_posts) > 0:
        print(f"\nğŸ“ˆ Top 5 by relevance score:")
        for i, post in enumerate(all_posts[:5], 1):
            print(f"{i}. [{post['relevance_score']}] {post['channel_name']} - {post['date'][:10]}")
            print(f"   {post['text'][:100]}...")

    await client.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
